{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-6uVbt4ccWbCVv2JAtOF8NFXMuPNXs at 0x7efb6930fad0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Orange who?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1678925897,\n",
       "  \"id\": \"chatcmpl-6uVbt4ccWbCVv2JAtOF8NFXMuPNXs\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 4,\n",
       "    \"prompt_tokens\": 38,\n",
       "    \"total_tokens\": 42\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Orange who?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy matey! Asynchronous programming be like havin' a crew o' pirates workin' on different tasks at the same time. Ye see, instead o' waitin' for one task to be completed before startin' the next, ye can assign tasks to yer crew and let 'em work on 'em simultaneously. This way, ye can get more done in less time and keep yer ship sailin' smoothly. It be like havin' a lookout keepin' watch while the cook be preparin' the next meal and the navigator be plottin' the course. Each pirate be doin' their own thing, but all workin' together to keep the ship runnin' smoothly. Arrr, that be asynchronous programming in a pirate's tongue!\n"
     ]
    }
   ],
   "source": [
    "# example with a system message\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain asynchronous programming in the style of the pirate Blackbeard.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Para construir uma pipa, você precisará dos seguintes materiais:\n",
      "\n",
      "- Papel de seda ou papel de embrulho\n",
      "- Varetas de bambu ou de madeira\n",
      "- Linha de pipa\n",
      "- Tesoura\n",
      "- Cola\n",
      "- Régua\n",
      "\n",
      "Passo a passo:\n",
      "\n",
      "1. Corte duas varetas de bambu ou madeira com cerca de 90 cm de comprimento e outra vareta com cerca de 70 cm de comprimento.\n",
      "\n",
      "2. Una as duas varetas maiores em forma de cruz, deixando a menor no centro. Amarre as varetas com linha de pipa, fazendo um nó bem firme.\n",
      "\n",
      "3. Corte um pedaço de papel de seda ou papel de embrulho com cerca de 1 metro de comprimento e 80 cm de largura.\n",
      "\n",
      "4. Cole a vareta menor no centro do papel, na junção das varetas maiores.\n",
      "\n",
      "5. Dobre as bordas do papel para dentro, deixando uma margem de cerca de 2 cm. Cole as bordas com cola.\n",
      "\n",
      "6. Corte um pedaço de linha de pipa com cerca de 50 cm de comprimento e amarre uma ponta na vareta menor, no centro da pipa. Passe a linha pelas varetas maiores, fazendo um nó na outra ponta.\n",
      "\n",
      "7. Corte um pedaço de linha de pipa com cerca de 3 metros de comprimento e amarre uma ponta na linha que está presa na pipa. Passe a linha pela vareta menor, fazendo um nó na outra ponta.\n",
      "\n",
      "8. Decore a pipa com desenhos ou pinturas, se desejar.\n",
      "\n",
      "9. Para soltar a pipa, segure a linha com as duas mãos e corra para frente, deixando a pipa subir. Para controlar a altura da pipa, solte ou puxe a linha.\n",
      "\n",
      "Lembre-se de soltar a pipa em locais abertos e sem fios elétricos ou árvores próximas. Tenha cuidado para não machucar outras pessoas ou animais.\n"
     ]
    }
   ],
   "source": [
    "# example without a system message\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Como construir uma pipa?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Fractions are a way of representing a part of a whole. The top number of a fraction is called the numerator, and it represents how many parts of the whole we are talking about. The bottom number is called the denominator, and it represents how many equal parts the whole is divided into.\n",
      "\n",
      "For example, if we have a pizza that is divided into 8 equal slices, and we take 3 slices, we can represent that as the fraction 3/8. The numerator is 3 because we took 3 slices, and the denominator is 8 because the pizza was divided into 8 slices.\n",
      "\n",
      "To add or subtract fractions, we need to have a common denominator. This means that the denominators of the fractions need to be the same. To do this, we can find the least common multiple (LCM) of the denominators and then convert each fraction to an equivalent fraction with the LCM as the denominator.\n",
      "\n",
      "To multiply fractions, we simply multiply the numerators together and the denominators together. To divide fractions, we multiply the first fraction by the reciprocal of the second fraction (flip the second fraction upside down).\n",
      "\n",
      "Now, here's a question to check for understanding: If we have a pizza that is divided into 12 equal slices, and we take 4 slices, what is the fraction that represents how much of the pizza we took?\n"
     ]
    }
   ],
   "source": [
    "# An example of a system message that primes the assistant to explain concepts in great depth\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a friendly and helpful teaching assistant. You explain concepts in great depth using simple terms, and you give examples to help people learn. At the end of each explanation, you ask a question to check for understanding\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain how fractions work?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have enough time to complete the entire project perfectly.\n"
     ]
    }
   ],
   "source": [
    "# An example of a faked few-shot conversation to prime the model into translating business jargon to simpler speech\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
    "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
    "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esse atraso na mudança de direção significa que não temos tempo para gastar recursos em coisas que não são importantes para o cliente.\n"
     ]
    }
   ],
   "source": [
    "# The business jargon translation example, but with example names for the example messages\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um assistente útil e seguidor de padrões que traduz o jargão corporativo para o Portugues simples.\"},\n",
    "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Novas sinergias ajudarão a impulsionar o crescimento da receita.\"},\n",
    "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Coisas que funcionam bem juntas aumentarão a receita.\"},\n",
    "        {\"role\": \"system\", \"name\":\"example_user\", \"content\": \"Vamos voltar quando tivermos mais largura de banda para tocar na base das oportunidades de maior alavancagem.\"},\n",
    "        {\"role\": \"system\", \"name\": \"example_assistant\", \"content\": \"Vamos conversar mais tarde, quando estivermos menos ocupados, sobre como fazer melhor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Esse pivô tardio significa que não temos tempo para ferver o oceano para a entrega do cliente.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A chat API call has two required inputs:\n",
    "\n",
    "model: the name of the model you want to use (e.g., gpt-3.5-turbo)\n",
    "messages: a list of message objects, where each object has at least two fields:\n",
    "role: the role of the messenger (either system, user, or assistant)\n",
    "content: the content of the message (e.g., Write me a beautiful poem)\n",
    "Typically, a conversation will start with a system message, followed by alternating user and assistant messages, but you are not required to follow this format.\n",
    "\n",
    "Let's look at an example chat API calls to see how the chat format works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-6uVvJDMqmd8smyvtvZ7fuYVSB8WbG at 0x7efb693997f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Leonardo da Vinci foi um dos mais famosos pintores do Renascimento italiano. Ele nasceu em 1452 e faleceu em 1519. Entre suas obras mais conhecidas est\\u00e3o a \\\"Mona Lisa\\\" e \\\"A \\u00daltima Ceia\\\". Al\\u00e9m de pintor, Leonardo da Vinci tamb\\u00e9m foi um inventor, cientista e escritor, sendo considerado um dos maiores g\\u00eanios da hist\\u00f3ria da humanidade.\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1678927101,\n",
       "  \"id\": \"chatcmpl-6uVvJDMqmd8smyvtvZ7fuYVSB8WbG\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 93,\n",
       "    \"prompt_tokens\": 50,\n",
       "    \"total_tokens\": 143\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um assistente que entende o mundo infantil.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Quem foi Leonardo da Vinci?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Em qual parte?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Pintor.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leonardo da Vinci foi um dos mais famosos pintores do Renascimento italiano. Ele nasceu em 1452 e faleceu em 1519. Entre suas obras mais conhecidas estão a \"Mona Lisa\" e \"A Última Ceia\". Além de pintor, Leonardo da Vinci também foi um inventor, cientista e escritor, sendo considerado um dos maiores gênios da história da humanidade.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Frações são uma forma de representar uma parte de um todo. Elas são compostas por dois números: o numerador e o denominador. O numerador representa a quantidade de partes que estamos considerando, enquanto o denominador representa o número total de partes que compõem o todo.\n",
      "\n",
      "Por exemplo, se tivermos uma pizza dividida em 8 pedaços e pegarmos 3 desses pedaços, podemos representar isso como a fração 3/8. O numerador é 3, pois estamos considerando 3 pedaços, e o denominador é 8, pois a pizza é dividida em 8 pedaços no total.\n",
      "\n",
      "É importante lembrar que as frações podem ser simplificadas, ou seja, podemos dividir o numerador e o denominador por um mesmo número para obter uma fração equivalente. Por exemplo, a fração 6/12 pode ser simplificada para 1/2, dividindo ambos por 6.\n",
      "\n",
      "Agora, para verificar a compreensão, me responda: o que representa o numerador e o denominador em uma fração?\n"
     ]
    }
   ],
   "source": [
    "# An example of a system message that primes the assistant to explain concepts in great depth\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você é um assistente de ensino amigável e útil. Você explica conceitos em grande profundidade usando termos simples e dá exemplos para ajudar as pessoas a aprender. Ao final de cada explicação, você faz uma pergunta para verificar a compreensão\"},\n",
    "        {\"role\": \"user\", \"content\": \"Pode me explicar como funciona as frações?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frações são números que representam uma parte de um todo. Elas são compostas por dois números, o numerador e o denominador, separados por uma linha horizontal. O numerador representa a quantidade de partes que estamos considerando, enquanto o denominador representa o número total de partes que compõem o todo. Por exemplo, a fração 1/2 representa uma metade de um todo, enquanto a fração 3/4 representa três quartos de um todo. As frações são muito usadas em matemática, especialmente em situações que envolvem divisão de quantidades em partes iguais.\n"
     ]
    }
   ],
   "source": [
    "# An example of a system message that primes the assistant to explain concepts in great depth\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Você ensina crianças de ate 6 anos.\"},\n",
    "        {\"role\": \"user\", \"content\": \"O que sao frações?\"},\n",
    "    ],\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage\n",
      "!”\n",
      "\n",
      "(p. 7~10)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "# list models\n",
    "models = openai.Model.list()\n",
    "\n",
    "# print the first model's id\n",
    "print(models.data[0].id)\n",
    "\n",
    "# create a completion\n",
    "completion = openai.Completion.create(model=\"ada\", prompt=\"Hello world\")\n",
    "\n",
    "# print the completion\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prompt\n",
    "\n",
    "prompt.get_response(\"Bom dia\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
